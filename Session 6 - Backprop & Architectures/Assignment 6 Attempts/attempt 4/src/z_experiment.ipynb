{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import *\n",
    "from models import *\n",
    "from utils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2 # %autoreload 0. disables autoloading. 2 enables autoreload ALL\n",
    "\n",
    "import torch\n",
    "import torch.optim as torch_optimizer # by naming it optimizer, it will conflict with the optimizer instantiated class\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "RANDOM_SEED = 42\n",
    "LEARNING_RATE = 0.01\n",
    "BATCH_SIZE = 64\n",
    "N_EPOCHS = 15\n",
    "\n",
    "IMG_SIZE = 32\n",
    "N_CLASSES = 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Data Loaders\"\n",
    "kwargs = {'batch_size': BATCH_SIZE, 'shuffle': True}\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, **kwargs)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, **kwargs)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "batch_data, batch_label = next(iter(train_dataloader)) \n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(12):\n",
    "  plt.subplot(3,4,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(batch_data[i].squeeze(0), cmap='gray')\n",
    "  plt.title(batch_label[i].item())\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model & Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FirstDNN()\n",
    "\n",
    "!pip install torchinfo\n",
    "from torchinfo import summary\n",
    "summary(model,input_size=(1,28,28),verbose=2);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = FirstDNN()\n",
    "errorFun = torch.nn.functional.nll_loss\n",
    "optimizer = torch_optimizer.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class reshape(nn.Module):\n",
    "    def __init__(self,pixels):\n",
    "        super().__init__()\n",
    "        self.pixels = pixels\n",
    "    def forward(self,x):\n",
    "        x = x.view(-1,self.pixels)\n",
    "        return x\n",
    "\n",
    "container = {                          \t\t\t\t\n",
    "            \"conv1\": nn.Conv2d(1,32,(3,3),1,1),     \n",
    "            \"relu\": nn.ReLU(), \n",
    "            \"conv2\": nn.Conv2d(32,32,(3,3),1,1),    \n",
    "            \"relu\": nn.ReLU(),\n",
    "                                                    \n",
    "            \"pool1\": nn.MaxPool2d((2,2),2,0),       \n",
    "\n",
    "            \"conv3\": nn.Conv2d(32,32,(3,3),1,1),   \n",
    "            \"relu\": nn.ReLU(),\n",
    "            \"conv4\": nn.Conv2d(32,32,(3,3),1,1),  \n",
    "            \"relu\": nn.ReLU(),\n",
    "                                                    \n",
    "            \"pool2\": nn.MaxPool2d((2,2),2,0),       \n",
    "            \n",
    "            \"conv5\": nn.Conv2d(32,32,(3,3),1,0),  \n",
    "            \"relu\": nn.ReLU(),\n",
    "            \"conv6\": nn.Conv2d(32,32,(3,3),1,0),  \n",
    "            \"relu\": nn.ReLU(),\n",
    "\n",
    "\t\t\t\"conv7\" : nn.Conv2d(32, 10, 3),\n",
    "\t\t\t\"reshaper\": reshape(10),\n",
    "\t\t\t\"log_softmax\": nn.LogSoftmax(dim=1),  \n",
    "            \n",
    "\n",
    "            # \"reshaper\": reshape(1024*9),\n",
    "            # \"fc1\": nn.Linear(1024*3*3,50),               \n",
    "            # \"relu\": nn.ReLU(),\n",
    "            # \"fc2\": nn.Linear(50,10),                \n",
    "            # \"softmax\": nn.LogSoftmax(dim=1),           \n",
    "            # Using softmax to check if probability sum == 1\n",
    "\n",
    "        }\n",
    "new_model = nn.Sequential(*container.values())\n",
    "summary(new_model,input_size=(1,28,28),verbose=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 5):\n",
    "\ttrain(train_dataloader, new_model, errorFun, optimizer,epoch)\n",
    "\ttest(test_dataloader, new_model, errorFun)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,2,figsize=(15,10))\n",
    "axs[0, 0].plot(training_losses_epochwise)\n",
    "axs[0, 0].set_title(\"Training Loss\")\n",
    "axs[1, 0].plot(training_accuracy_epochwise)\n",
    "axs[1, 0].set_title(\"Training Accuracy\")\n",
    "axs[0, 1].plot(test_losses_epochwise)\n",
    "axs[0, 1].set_title(\"Test Loss\")\n",
    "axs[1, 1].plot(test_accuracy_epochwise)\n",
    "axs[1, 1].set_title(\"Test Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
